# DataLoader
batch_size: 8        # 训练时的 batch size for parallel processing

test_batch_size: 8     # 验证/测试时的 batch size

# Optimization
learning_rate: 0.002   # 初始学习率
weight_decay: 0.0001   # 权重衰减

# Training schedule
epochs: 10             # 总训练轮数
clip_grad_norm: 1.0    # 梯度裁剪阈值

# LR scheduler
lr_step: 1             # 每隔多少 epoch 衰减一次
lr_gamma: 0.95         # 衰减倍率
